{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nnunet2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOWdby98C7IoHoU4tvchbKf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohsenhariri/blog/blob/main/nnunet2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eeYrVL_LtpVS",
        "outputId": "defee5ba-fa5c-4005-f3f6-7fe52cdfd6b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SimpleITK==2.0.2\n",
            "  Downloading SimpleITK-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (47.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.4 MB 1.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-2.0.2\n",
            "Collecting nnunet\n",
            "  Downloading nnunet-1.7.0.tar.gz (251 kB)\n",
            "\u001b[K     |████████████████████████████████| 251 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6.0a in /usr/local/lib/python3.7/dist-packages (from nnunet) (1.10.0+cu111)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nnunet) (4.64.0)\n",
            "Collecting dicom2nifti\n",
            "  Downloading dicom2nifti-2.3.2.tar.gz (35 kB)\n",
            "Requirement already satisfied: scikit-image>=0.14 in /usr/local/lib/python3.7/dist-packages (from nnunet) (0.18.3)\n",
            "Collecting medpy\n",
            "  Downloading MedPy-0.4.0.tar.gz (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 42.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from nnunet) (1.4.1)\n",
            "Collecting batchgenerators>=0.23\n",
            "  Downloading batchgenerators-0.23.tar.gz (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from nnunet) (1.21.6)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from nnunet) (0.0)\n",
            "Requirement already satisfied: SimpleITK in /usr/local/lib/python3.7/dist-packages (from nnunet) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from nnunet) (1.3.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from nnunet) (2.23.0)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.7/dist-packages (from nnunet) (3.0.2)\n",
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.7/dist-packages (from nnunet) (2021.11.2)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from batchgenerators>=0.23->nnunet) (7.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from batchgenerators>=0.23->nnunet) (1.0.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from batchgenerators>=0.23->nnunet) (0.16.0)\n",
            "Collecting unittest2\n",
            "  Downloading unittest2-1.1.0-py2.py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl in /usr/local/lib/python3.7/dist-packages (from batchgenerators>=0.23->nnunet) (3.1.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14->nnunet) (3.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14->nnunet) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14->nnunet) (1.3.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14->nnunet) (2.6.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14->nnunet) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14->nnunet) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14->nnunet) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14->nnunet) (3.0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14->nnunet) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14->nnunet) (1.15.0)\n",
            "Collecting pydicom>=1.3.0\n",
            "  Downloading pydicom-2.3.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 61.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->nnunet) (2022.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->nnunet) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->nnunet) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->nnunet) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->nnunet) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->batchgenerators>=0.23->nnunet) (1.1.0)\n",
            "Collecting argparse\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Collecting traceback2\n",
            "  Downloading traceback2-1.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting linecache2\n",
            "  Downloading linecache2-1.0.0-py2.py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: nnunet, batchgenerators, dicom2nifti, medpy\n",
            "  Building wheel for nnunet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nnunet: filename=nnunet-1.7.0-py3-none-any.whl size=487821 sha256=d64a6ac67e3ee333a3337b0d2ae89bc92ce7bed2f46117413cf873746c7c7adf\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/f6/19/c51389976a9ae30212178d1c41497893504b900f043fe1c665\n",
            "  Building wheel for batchgenerators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for batchgenerators: filename=batchgenerators-0.23-py3-none-any.whl size=84779 sha256=37de2baf7305d1b2d4acffb9c4e232af8519e9660a2d1420b5b2931fc24d67d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/3d/a2/9a602ce56458c684d2962ec89eddd6bc06b00687735e2dd11a\n",
            "  Building wheel for dicom2nifti (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dicom2nifti: filename=dicom2nifti-2.3.2-py3-none-any.whl size=44320 sha256=727cb62123656ae2bca893f88eb02a6670d0b6cc06057648720e203a20b17666\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/98/eb/c8647e1916efdcc53523d229393409c514cd2807414fcf603e\n",
            "  Building wheel for medpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for medpy: filename=MedPy-0.4.0-cp37-cp37m-linux_x86_64.whl size=754464 sha256=7ef87be05dff5d4325ec6bbab3f10d8a3c3525ff98bea6f256f2da01755c118c\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/57/3a/da1183f22a6afb42e11138daa6a759de233fd977a984333602\n",
            "Successfully built nnunet batchgenerators dicom2nifti medpy\n",
            "Installing collected packages: linecache2, traceback2, argparse, unittest2, pydicom, medpy, dicom2nifti, batchgenerators, nnunet\n",
            "Successfully installed argparse-1.4.0 batchgenerators-0.23 dicom2nifti-2.3.2 linecache2-1.0.0 medpy-0.4.0 nnunet-1.7.0 pydicom-2.3.0 traceback2-1.4.0 unittest2-1.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Please cite the following paper when using nnUNet:\n",
            "\n",
            "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
            "\n",
            "\n",
            "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
            "\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from collections import OrderedDict\n",
        "\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import nibabel as nib\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "!pip install SimpleITK==2.0.2\n",
        "\n",
        "!pip install nnunet \n",
        "\n",
        "import nnunet\n",
        "\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount = True)\n",
        "\n",
        "drive_dir = \"/content/drive/My Drive\"\n",
        "mount_dir = os.path.join(drive_dir, \"Colab Notebooks\")\n",
        "base_dir = os.getcwd()\n",
        "\n",
        "\n",
        "assert os.path.exists(drive_dir) # if this fails, something went wrong with mounting GoogleDrive\n",
        "if os.path.exists(mount_dir) is False:\n",
        "    os.makedirs(mount_dir)\n",
        "\n",
        "\n",
        "def make_if_dont_exist(folder_path,overwrite=False):\n",
        "    \"\"\"\n",
        "    creates a folder if it does not exists\n",
        "    input: \n",
        "    folder_path : relative path of the folder which needs to be created\n",
        "    over_write :(default: False) if True overwrite the existing folder \n",
        "    \"\"\"\n",
        "    if os.path.exists(folder_path):\n",
        "        \n",
        "        if not overwrite:\n",
        "            print(f\"{folder_path} exists.\")\n",
        "        else:\n",
        "            print(f\"{folder_path} overwritten\")\n",
        "            shutil.rmtree(folder_path)\n",
        "            os.makedirs(folder_path)\n",
        "\n",
        "    else:\n",
        "      os.makedirs(folder_path)\n",
        "      print(f\"{folder_path} created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "U6vKuY4g_nqF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "9hoiHN-n_oPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Maybe move path of preprocessed data directly on content - this may be signifcantely faster!\n",
        "print(\"Current Working Directory {}\".format(os.getcwd()))\n",
        "path_dict = {\n",
        "    \"nnUNet_raw_data_base\" : os.path.join(mount_dir, \"nnUNet_raw_data_base\"), \n",
        "    \"nnUNet_preprocessed\" : os.path.join(mount_dir, \"nnUNet_preprocessed\"), # 1 experiment: 1 epoch took 112s\n",
        "    # \"nnUNet_preprocessed\" : os.path.join(base_dir, \"nnUNet_preprocessed\"), # 1 experiment: 1 epoch took 108s -> seems faster take this\n",
        "    \"RESULTS_FOLDER\" : os.path.join(mount_dir, \"nnUNet_Results_Folder\"),\n",
        "    \"RAW_DATA_PATH\" : os.path.join(mount_dir, \"RawData\"), # This is used here only for convenience (not necessary for nnU-Net)!\n",
        "}\n",
        "\n",
        "# Write paths to environment variables\n",
        "for env_var, path in path_dict.items():\n",
        "  os.environ[env_var] = path \n",
        "\n",
        "# Check whether all environment variables are set correct!\n",
        "for env_var, path in path_dict.items():\n",
        "  if os.getenv(env_var) != path:\n",
        "    print(\"Error:\")\n",
        "    print(\"Environment Variable {} is not set correctly!\".format(env_var))\n",
        "    print(\"Should be {}\".format(path))\n",
        "    print(\"Variable is {}\".format(os.getenv(env_var)))\n",
        "  make_if_dont_exist(path, overwrite=False)\n",
        "\n",
        "print(\"If No Error Occured Continue Forward. =)\")"
      ],
      "metadata": {
        "id": "JtUWVPneuEps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adb62532-b1f6-44e0-a70b-702d7eac97ae"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Working Directory /content\n",
            "/content/drive/My Drive/Colab Notebooks/nnUNet_raw_data_base exists.\n",
            "/content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed exists.\n",
            "/content/drive/My Drive/Colab Notebooks/nnUNet_Results_Folder exists.\n",
            "/content/drive/My Drive/Colab Notebooks/RawData exists.\n",
            "If No Error Occured Continue Forward. =)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNet_download_pretrained_model Task001_BrainTumour "
      ],
      "metadata": {
        "id": "ogJ79Y6PuS7R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fce27c24-4ff7-4242-8323-d3c2e74ebefb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Please cite the following paper when using nnUNet:\n",
            "\n",
            "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
            "\n",
            "\n",
            "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
            "\n",
            "\n",
            "######################################################\n",
            "!!!!!!!!!!!!!!!!!!!!!!!!WARNING!!!!!!!!!!!!!!!!!!!!!!!\n",
            "######################################################\n",
            "Using the pretrained model weights is subject to the license of the dataset they were trained on. Some allow commercial use, others don't. It is your responsibility to make sure you use them appropriately! Use nnUNet_print_pretrained_model_info(task_name) to see a summary of the dataset and where to find its license!\n",
            "######################################################\n",
            "\n",
            "Downloading pretrained model from url: https://zenodo.org/record/4003545/files/Task001_BrainTumour.zip?download=1\n",
            "Download finished. Extracting...\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls drive/MyDrive/'Colab Notebooks'/nnUNet_raw_data_base/nnUNet_raw_data/Task001_BrainTumour/imagesTs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrGbs6XUx8Ku",
        "outputId": "f97d3c48-f065-40eb-dda9-851697cf4636"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BRATS_001_0000.nii.gz  BRATS_001_0002.nii.gz\n",
            "BRATS_001_0001.nii.gz  BRATS_001_0003.nii.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNet_predict -i drive/MyDrive/'Colab Notebooks'/nnUNet_raw_data_base/nnUNet_raw_data/Task001_BrainTumour/imagesTs -o OUTPUT_DIRECTORY -t Task001_BrainTumour\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCOwYxoSIOQ9",
        "outputId": "9d22b152-8705-44cf-911e-6773c8c3973b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Please cite the following paper when using nnUNet:\n",
            "\n",
            "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
            "\n",
            "\n",
            "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
            "\n",
            "using model stored in  /content/drive/My Drive/Colab Notebooks/nnUNet_Results_Folder/nnUNet/3d_fullres/Task001_BrainTumour/nnUNetTrainerV2__nnUNetPlansv2.1\n",
            "This model expects 4 input modalities for each image\n",
            "Found 1 unique case ids, here are some examples: ['BRATS_001']\n",
            "If they don't look right, make sure to double check your filenames. They must end with _0000.nii.gz etc\n",
            "number of cases: 1\n",
            "number of cases that still need to be predicted: 1\n",
            "emptying cuda cache\n",
            "loading parameters for folds, None\n",
            "folds is None so we will automatically look for output folders (not using 'all'!)\n",
            "found the following folds:  ['/content/drive/My Drive/Colab Notebooks/nnUNet_Results_Folder/nnUNet/3d_fullres/Task001_BrainTumour/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0', '/content/drive/My Drive/Colab Notebooks/nnUNet_Results_Folder/nnUNet/3d_fullres/Task001_BrainTumour/nnUNetTrainerV2__nnUNetPlansv2.1/fold_1', '/content/drive/My Drive/Colab Notebooks/nnUNet_Results_Folder/nnUNet/3d_fullres/Task001_BrainTumour/nnUNetTrainerV2__nnUNetPlansv2.1/fold_2', '/content/drive/My Drive/Colab Notebooks/nnUNet_Results_Folder/nnUNet/3d_fullres/Task001_BrainTumour/nnUNetTrainerV2__nnUNetPlansv2.1/fold_3', '/content/drive/My Drive/Colab Notebooks/nnUNet_Results_Folder/nnUNet/3d_fullres/Task001_BrainTumour/nnUNetTrainerV2__nnUNetPlansv2.1/fold_4']\n",
            "using the following model files:  ['/content/drive/My Drive/Colab Notebooks/nnUNet_Results_Folder/nnUNet/3d_fullres/Task001_BrainTumour/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0/model_final_checkpoint.model', '/content/drive/My Drive/Colab Notebooks/nnUNet_Results_Folder/nnUNet/3d_fullres/Task001_BrainTumour/nnUNetTrainerV2__nnUNetPlansv2.1/fold_1/model_final_checkpoint.model', '/content/drive/My Drive/Colab Notebooks/nnUNet_Results_Folder/nnUNet/3d_fullres/Task001_BrainTumour/nnUNetTrainerV2__nnUNetPlansv2.1/fold_2/model_final_checkpoint.model', '/content/drive/My Drive/Colab Notebooks/nnUNet_Results_Folder/nnUNet/3d_fullres/Task001_BrainTumour/nnUNetTrainerV2__nnUNetPlansv2.1/fold_3/model_final_checkpoint.model', '/content/drive/My Drive/Colab Notebooks/nnUNet_Results_Folder/nnUNet/3d_fullres/Task001_BrainTumour/nnUNetTrainerV2__nnUNetPlansv2.1/fold_4/model_final_checkpoint.model']\n",
            "starting preprocessing generator\n",
            "starting prediction...\n",
            "preprocessing OUTPUT_DIRECTORY/BRATS_001.nii.gz\n",
            "using preprocessor GenericPreprocessor\n",
            "before crop: (4, 155, 240, 240) after crop: (4, 132, 176, 136) spacing: [1. 1. 1.] \n",
            "\n",
            "no resampling necessary\n",
            "no resampling necessary\n",
            "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (4, 132, 176, 136)} \n",
            "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (4, 132, 176, 136)} \n",
            "\n",
            "(4, 132, 176, 136)\n",
            "This worker has ended successfully, no errors to report\n",
            "predicting OUTPUT_DIRECTORY/BRATS_001.nii.gz\n",
            "/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
            "debug: mirroring True mirror_axes (0, 1, 2)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
            "step_size: 0.5\n",
            "do mirror: True\n",
            "data shape: (4, 132, 176, 136)\n",
            "patch size: [128 128 128]\n",
            "steps (x, y, and z): [[0, 4], [0, 48], [0, 8]]\n",
            "number of tiles: 8\n",
            "computing Gaussian\n",
            "prediction done\n",
            "debug: mirroring True mirror_axes (0, 1, 2)\n",
            "step_size: 0.5\n",
            "do mirror: True\n",
            "data shape: (4, 132, 176, 136)\n",
            "patch size: [128 128 128]\n",
            "steps (x, y, and z): [[0, 4], [0, 48], [0, 8]]\n",
            "number of tiles: 8\n",
            "using precomputed Gaussian\n",
            "prediction done\n",
            "debug: mirroring True mirror_axes (0, 1, 2)\n",
            "step_size: 0.5\n",
            "do mirror: True\n",
            "data shape: (4, 132, 176, 136)\n",
            "patch size: [128 128 128]\n",
            "steps (x, y, and z): [[0, 4], [0, 48], [0, 8]]\n",
            "number of tiles: 8\n",
            "using precomputed Gaussian\n",
            "prediction done\n",
            "debug: mirroring True mirror_axes (0, 1, 2)\n",
            "step_size: 0.5\n",
            "do mirror: True\n",
            "data shape: (4, 132, 176, 136)\n",
            "patch size: [128 128 128]\n",
            "steps (x, y, and z): [[0, 4], [0, 48], [0, 8]]\n",
            "number of tiles: 8\n",
            "using precomputed Gaussian\n",
            "prediction done\n",
            "debug: mirroring True mirror_axes (0, 1, 2)\n",
            "step_size: 0.5\n",
            "do mirror: True\n",
            "data shape: (4, 132, 176, 136)\n",
            "patch size: [128 128 128]\n",
            "steps (x, y, and z): [[0, 4], [0, 48], [0, 8]]\n",
            "number of tiles: 8\n",
            "using precomputed Gaussian\n",
            "prediction done\n",
            "inference done. Now waiting for the segmentation export to finish...\n",
            "force_separate_z: None interpolation order: 1\n",
            "no resampling necessary\n",
            "postprocessing...\n"
          ]
        }
      ]
    }
  ]
}